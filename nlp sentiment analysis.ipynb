{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Setting the option  to display the entire text row\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð??±!!! ð???ð???ð???ð???ð??¦ð??¦ð??¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ð??ð??ð??ð??ð??ð??ð??ð??ð??â¤ï¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisolm. #shame #imwithher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw to work is sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary, #wso condemns  act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "0      1      0       \n",
       "1      2      0       \n",
       "2      3      0       \n",
       "3      4      0       \n",
       "4      5      0       \n",
       "...   ..     ..       \n",
       "31957  31958  0       \n",
       "31958  31959  0       \n",
       "31959  31960  0       \n",
       "31960  31961  1       \n",
       "31961  31962  0       \n",
       "\n",
       "                                                                                                                                     tweet  \n",
       "0       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                               \n",
       "1      @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked           \n",
       "2        bihday your majesty                                                                                                                \n",
       "3      #model   i love u take with u all the time in urð??±!!! ð???ð???ð???ð???ð??¦ð??¦ð??¦                                                 \n",
       "4       factsguide: society now    #motivation                                                                                              \n",
       "...                                        ...                                                                                              \n",
       "31957  ate @user isz that youuu?ð??ð??ð??ð??ð??ð??ð??ð??ð??â¤ï¸                                                                  \n",
       "31958    to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisolm. #shame #imwithher  \n",
       "31959  listening to sad songs on a monday morning otw to work is sad                                                                        \n",
       "31960  @user #sikh #temple vandalised in in #calgary, #wso condemns  act                                                                    \n",
       "31961  thank you @user for you follow                                                                                                       \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data set\n",
    "#dr=\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\"\n",
    "df_train=pd.read_csv(\"train_E6oV3lV.csv\",encoding=\"ISO-8859-1\")\n",
    "df_train\n",
    "\n",
    "# There are three columns\n",
    "# 1: id\n",
    "# 2: label (1 and 0)\n",
    "# 3: tweet (text form)\n",
    "\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n",
    "# 31962 rows and three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the frequency distribution\n",
    "df_train['label'].value_counts()\n",
    "# 29720 '0'\n",
    "# 2242 '1'\n",
    "zeroes_cnt=df_train['label'].value_counts()[0]\n",
    "ones_cnt=df_train['label'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data set\n",
    "# creating the stop word list\n",
    "# Removing rows corresponding to stop word\n",
    "# Stop word removal using inbuilt and custom list\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop2=list(stop)\n",
    "stop2.extend(['@user','@user @user','&amp;','@user @user @user','-','u','Ã¢Â€Â“',\n",
    "             'Ã¢Â€Â”','Ã¢Â€Â¦','Ã¢Â†Â','Ã¢ÂÂ¤','Ã¢ÂÂ¤Ã¯Â¸Â','Ã°ÂŸÂ’Â•','Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "             'Ã°ÂŸÂ”Â','Ã°ÂŸÂ”Â  #love','Ã°ÂŸÂ”Â  #love  #instagood',\n",
    "             'Ã°ÂŸÂ˜','Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â„',\n",
    "            'Ã°ÂŸÂ˜ÂŠ','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â”','Ã°ÂŸÂ˜Â˜','Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "            'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦','Ã°ÂŸÂ˜Â¢',\n",
    "             'Ã¢Â€Â¦','!!','!!!','Ã¢Â€Â¦',        'Ã¢Â€Â¦','2','Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "            'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦','Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "            '...','Ã¢Â†Â','4','1','3','Ã°ÂŸÂ˜ÂŠ','Ã¢ÂÂ¤Ã¯Â¸Â','.@user','#a','5',':(','Ã°ÂŸÂ˜Â','Ã¢Â€Â“',\n",
    "            '..','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â”','10','Ã°ÂŸÂ˜Â','1st','7','Ã°ÂŸÂ˜Â¢','#Ã¢Â€Â¦','6','Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â˜',\n",
    "              'Ã°ÂŸÂ’Â•','Ã°ÂŸÂ”Â','Ã¢ÂÂ¤','Ã°ÂŸÂ˜Â„','Ã°ÂŸÂ”Â  #love','50','2nd','8','Ã¢Â€Â”','Ã°ÂŸÂ˜','3d:',\n",
    "                'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91  ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
    "              'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘Â…Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to analyse the text data stored in the 'tweet' column\n",
    "# Before that lets define some key functions\n",
    "# Creating functions to do tokenisation and punctuation removal\n",
    "\n",
    "# White space tokenizer\n",
    "def tokenize(text):\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    token = []\n",
    "    for item in text:\n",
    "        token.append(tokenizer.tokenize(item))\n",
    "        \n",
    "    # Removing stop words\n",
    "    ls_dummy1=[]\n",
    "    ls_dummy2=[]\n",
    "    temp=1\n",
    "    for i in token:\n",
    "        ls_dummy1=[]\n",
    "        for j in i:\n",
    "            if j in stop2:\n",
    "                temp=1\n",
    "            else:\n",
    "                ls_dummy1.append(j)\n",
    "        ls_dummy2.append(ls_dummy1)\n",
    "    l3=ls_dummy2\n",
    "        \n",
    "    return l3\n",
    "\n",
    "# Creating a function for removing the puntuation from text\n",
    "def rem_punctuation(data_frame,colname):\n",
    "    l3=[]\n",
    "    l2=[i for i in data_frame[colname]]\n",
    "    l3=tokenize(l2)\n",
    "\n",
    "    # Removing the punctuations\n",
    "    l5=[]\n",
    "    l6=[]\n",
    "    for j in l3:\n",
    "        for k in j:\n",
    "            if k in string.punctuation:\n",
    "                temp=1\n",
    "            else:\n",
    "                l5.append(k)\n",
    "        l6.append(l5)\n",
    "        l5=[]\n",
    "    c_ls=[\" \".join(i) for i in l6]\n",
    "    df1=pd.DataFrame(c_ls)\n",
    "    df1.columns=['Text']\n",
    "    return(df1)\n",
    "\n",
    "# We will now create a function that takes in text and ngram list\n",
    "# text/document is stores in a list\n",
    "# list also specifies ngram paramter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# The function should take the column containing text data\n",
    "def TF_NGRAM(data_frame,colname,ngram):\n",
    "    # Tokenize the data\n",
    "    DocID_ls=[]\n",
    "\n",
    "    #Appending the Doc_ID column\n",
    "    data_frame['Doc_ID']=[i for i in range(1,data_frame[colname].shape[0]+1)]\n",
    "\n",
    "\n",
    "    from nltk import ngrams       \n",
    "    l1=[]\n",
    "    for i in data_frame['Doc_ID']:\n",
    "        for k in data_frame[data_frame['Doc_ID']==i][colname]:\n",
    "            for j in ngram:\n",
    "                unigrams = ngrams(k.split(), j)\n",
    "                for z in unigrams:\n",
    "                    if j==1:\n",
    "                        l1.append(z[0])\n",
    "                    elif j==2:\n",
    "                        l1.append(z[0] + \" , \" +z[1])\n",
    "                    elif j==3:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2])\n",
    "                    elif j==4:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2] +\" , \" +z[3])\n",
    "\n",
    "                    DocID_ls.append(i)\n",
    "\n",
    "    # Creating a Data Frame out of it\n",
    "\n",
    "    s1=pd.Series(l1)\n",
    "    s2=pd.Series(DocID_ls)\n",
    "    df1=pd.DataFrame(s2)\n",
    "    df1['s1']=s1\n",
    "    df1.columns=['Doc_ID','Tokens']\n",
    "    df1\n",
    "    return(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur??!!! ??????????????????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0  1   0       \n",
       "1  2   0       \n",
       "2  3   0       \n",
       "3  4   0       \n",
       "4  5   0       \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in ur??!!! ??????????????????                                                    \n",
       "4   factsguide: society now    #motivation                                                                                     "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you look closely, there are certain characters such as Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¿Ã¢ÂœÂ (row 4 for instance)\n",
    "# These are meaningless and hence they need to be removed\n",
    "# Removing the special character/ascii character\n",
    "twt=[str(i).encode('ascii', 'ignore').decode(\"utf-8\") for i in df_train['tweet'] ]\n",
    "df_train['tweet']=twt\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the special characters doesnt reduce the number of records \n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations, stop words etc\n",
    "df=rem_punctuation(df_train,'tweet')\n",
    "df.head()\n",
    "df.to_csv(\"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>father dysfunctional selfish drags kids dysfunction. #run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks #lyft credit can't use cause offer wheelchair vans pdx. #disapointed #getthanked</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model love take time ur??!!! ??????????????????</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Text  \\\n",
       "0  father dysfunctional selfish drags kids dysfunction. #run                                 \n",
       "1  thanks #lyft credit can't use cause offer wheelchair vans pdx. #disapointed #getthanked   \n",
       "2  bihday majesty                                                                            \n",
       "3  #model love take time ur??!!! ??????????????????                                          \n",
       "4  factsguide: society #motivation                                                           \n",
       "\n",
       "   Doc_ID  \n",
       "0  1       \n",
       "1  2       \n",
       "2  3       \n",
       "3  4       \n",
       "4  5       "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Doc_ID']=range(1,df.shape[0]+1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# So no rows were removed during punctuation and stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the total number of blanks in df\n",
    "#len(np.where(df['Text'].applymap(lambda x: x == ''))[0]) # 19 ff them\n",
    "blnk_Doc_ID=df['Text']==\"\"\n",
    "df[blnk_Doc_ID].shape\n",
    "\n",
    "# There are 19 Doc_ID which are blank after Removing punctuations, stop words etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3982     3983 \n",
       "4411     4412 \n",
       "4799     4800 \n",
       "5235     5236 \n",
       "9034     9035 \n",
       "10802    10803\n",
       "13038    13039\n",
       "13287    13288\n",
       "13862    13863\n",
       "20261    20262\n",
       "28513    28514\n",
       "Name: Doc_ID, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the Doc_ID's that have blank in 'Text'\n",
    "ls_blnk_Doc_ID=df[blnk_Doc_ID]['Doc_ID']\n",
    "ls_blnk_Doc_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>#run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>father , dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional , selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>selfish , drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>drags , kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID                   Tokens\n",
       "0   1       father                 \n",
       "1   1       dysfunctional          \n",
       "2   1       selfish                \n",
       "3   1       drags                  \n",
       "4   1       kids                   \n",
       "5   1       dysfunction.           \n",
       "6   1       #run                   \n",
       "7   1       father , dysfunctional \n",
       "8   1       dysfunctional , selfish\n",
       "9   1       selfish , drags        \n",
       "10  1       drags , kids           "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram frequency analysis\n",
    "# checking the ngram distribution\n",
    "ngram_df=TF_NGRAM(df,'Text',[1,2,3])\n",
    "ngram_df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31951"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of unique 'Doc_ID' in ngram_df\n",
    "len(ngram_df['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID         Tokens\n",
       "0  1       father       \n",
       "1  1       dysfunctional\n",
       "2  1       selfish      \n",
       "3  1       drags        \n",
       "4  1       kids         "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all , in Tokens with \"\"\n",
    "import re\n",
    "ngram_df['Tokens']=ngram_df['Tokens'].apply(lambda x: re.sub(',','',x))\n",
    "ngram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Doc_ID', 'Tokens'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687224, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31951"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of unique 'Doc_ID' in ngram_df\n",
    "len(ngram_df['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we add the ones that had blanks in df (19 of them), then we would get 31962 which is the \n",
    "# total count of Doc_ID in the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID Tokens\n",
       "0  1       dummy\n",
       "1  2       dummy\n",
       "2  3       dummy\n",
       "3  4       dummy\n",
       "4  5       dummy"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Data Frame that has 'dummy' values for all Doc_ID\n",
    "#ls_blnk_Doc_ID=list(blnk_Doc_ID)\n",
    "\n",
    "blnk_df=pd.DataFrame(df['Doc_ID'],columns=['Doc_ID'])\n",
    "blnk_df['Tokens']='dummy'\n",
    "blnk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687224, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binding ngram_df and blnk_df row wise\n",
    "ngram_df2=pd.concat([ngram_df,blnk_df],axis=0)\n",
    "len(ngram_df2['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>drags  kids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drags  kids  dysfunction.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID                     Tokens  Frequency\n",
       "0  1       #run                       1        \n",
       "1  1       drags                      1        \n",
       "2  1       drags  kids                1        \n",
       "3  1       drags  kids  dysfunction.  1        \n",
       "4  1       dummy                      1        "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a summary at Doc_ID and Tokens level\n",
    "ngram_df2['Frequency']=1\n",
    "ngram_df0=ngram_df2.groupby(['Doc_ID','Tokens'])['Frequency'].sum().reset_index()\n",
    "ngram_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy</td>\n",
       "      <td>31962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>???</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#love</td>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Count\n",
       "0  dummy  31962\n",
       "1  ???    1521 \n",
       "2  day    1452 \n",
       "3  #love  1449 \n",
       "4  happy  1294 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the summary at an overall level\n",
    "freq_dist=nltk.FreqDist(ngram_df0['Tokens'])\n",
    "df5=pd.DataFrame(pd.Series(freq_dist),columns=['Count'])\n",
    "df5.sort_values(['Count'])\n",
    "df6=df5.sort_values(['Count'],ascending=False).reset_index()\n",
    "df6.shape # 827k records\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out the ngrams\n",
    "df7=df6[df6['Count'] > 50]\n",
    "df7.shape\n",
    "# For the first run lets keep features identified in df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the tokens to a file\n",
    "df7.to_csv(\"tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token=[i for i in df7['index']]\n",
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>can't</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID  Tokens  Frequency\n",
       "4   1       dummy   1        \n",
       "10  1       father  1        \n",
       "13  1       kids    1        \n",
       "25  2       can't   1        \n",
       "28  2       cause   1        "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DTM\n",
    "\n",
    "pos=[i in token for i in ngram_df0['Tokens']] # filtering on the tokens given in 'token' list\n",
    "ngram_df_DTM0=ngram_df0[pos]\n",
    "ngram_df_DTM0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154805, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df_DTM0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Tokens</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#?</th>\n",
       "      <th>#??</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Tokens  Doc_ID  #2016   #?  #??  #affirmation  #affirmations  #allahsoil  \\\n",
       "0       1       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "1       2       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "2       3       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "3       4       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "4       5       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "\n",
       "Tokens  #altwaystoheal  #altwaystoheal  #healthy  #amazing  ...  year  years  \\\n",
       "0       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "1       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "2       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "3       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "4       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "\n",
       "Tokens  yes  yet   yo  you  you!  you.  you?  young  \n",
       "0       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "1       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "2       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "3       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "4       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "\n",
       "[5 rows x 877 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivotting df3 \n",
    "ngram_df_DTM=ngram_df_DTM0.pivot(index='Doc_ID',columns='Tokens',values='Frequency').fillna(0).reset_index()\n",
    "ngram_df_DTM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 877)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df_DTM.shape\n",
    "# ngram_df_DTM has all the Doc_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the columns to a csv\n",
    "clm=ngram_df_DTM.columns\n",
    "np.array([clm])\n",
    "#pd.DataFrame(np.array([clm]).to_csv(\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\\\\final_features.csv\")\n",
    "ngram_df_DTM.to_csv(\"ngram_DTM.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 877)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension of ngram_df_DTM\n",
    "ngram_df_DTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 880)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining this with the 'id' column from input data frame(df_train) to bring in the labels \n",
    "\n",
    "# LEFT JOIN\n",
    "df_final=pd.merge(ngram_df_DTM,df_train,left_on='Doc_ID',right_on='id',how='left')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#?</th>\n",
       "      <th>#??</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur??!!! ??????????????????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  #2016   #?  #??  #affirmation  #affirmations  #allahsoil  \\\n",
       "0  1       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "1  2       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "2  3       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "3  4       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "4  5       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "\n",
       "   #altwaystoheal  #altwaystoheal  #healthy  #amazing  ...  yet   yo  you  \\\n",
       "0  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "1  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "2  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "3  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "4  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "\n",
       "   you!  you.  you?  young  id  label  \\\n",
       "0  0.0   0.0   0.0   0.0    1   0       \n",
       "1  0.0   0.0   0.0   0.0    2   0       \n",
       "2  0.0   0.0   0.0   0.0    3   0       \n",
       "3  0.0   0.0   0.0   0.0    4   0       \n",
       "4  0.0   0.0   0.0   0.0    5   0       \n",
       "\n",
       "                                                                                                                      tweet_y  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in ur??!!! ??????????????????                                                    \n",
       "4   factsguide: society now    #motivation                                                                                     \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm=pd.DataFrame(df_final.columns,columns=['Col_Name'])\n",
    "nm.to_csv(\"Final_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1    2242 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of ones in label column\n",
    "df_final['label'].value_counts()\n",
    "\n",
    "# in the input train data, following is the 0 and 1 distribution\n",
    "# 29720 '0'\n",
    "# 2242 '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for building the model\n",
    "# mostly it will be the functions around sklearn library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Feature Selection\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Independent variable list\n",
    "df_final.columns\n",
    "\n",
    "# Removing 'dummy' column from the list\n",
    "df_final2=df_final.drop(['Doc_ID','dummy','id','label','tweet_y'],axis=1)\n",
    "\n",
    "# Storing the IV list in X\n",
    "X=list(df_final2.columns)\n",
    "len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets run the Model\n",
    "# Splitting the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train=df_final[X]\n",
    "y_train = df_final['label']\n",
    "\n",
    "\n",
    "# Importing Logistic regression model from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Making an instance of the model\n",
    "LogisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.56767246e-01,  7.76077941e-01, -7.29563407e-01,\n",
       "        -7.48812844e-01, -4.85069722e-01,  5.16191925e+00,\n",
       "        -8.82608248e-01, -5.92450940e-01, -9.49921373e-01,\n",
       "        -5.68436000e-01, -8.07497179e-01, -7.66334381e-01,\n",
       "        -6.84346081e-01, -1.29328013e+00, -1.37227389e-02,\n",
       "        -5.23554424e-01, -1.79752241e+00,  1.41474222e+00,\n",
       "        -1.42632965e+00, -1.03905477e+00, -5.85968498e-01,\n",
       "        -3.48046170e-01, -8.45208519e-01, -1.35336607e+00,\n",
       "        -5.46155456e-01, -6.95296024e-01, -7.97663138e-02,\n",
       "        -7.97663138e-02, -1.50552649e+00, -4.57054152e-03,\n",
       "        -4.51509807e-03, -4.27156090e-01, -8.09488769e-01,\n",
       "        -1.49524319e+00, -1.07401616e-01, -1.03225986e+00,\n",
       "        -9.72591931e-01, -7.90779996e-02, -7.90779996e-02,\n",
       "        -7.90779996e-02, -1.12290541e+00, -7.93394775e-01,\n",
       "        -1.69472260e+00, -1.55860475e+00, -1.06342012e+00,\n",
       "        -5.57226933e-01, -6.45422959e-01, -5.94323777e-01,\n",
       "        -1.58579801e+00, -1.00327102e+00, -1.09168677e+00,\n",
       "        -8.17977013e-01, -6.15408989e-02, -4.75317730e-01,\n",
       "        -3.19725914e-01, -6.87906611e-01, -1.60662627e+00,\n",
       "        -6.94186344e-01, -1.21738475e-01, -1.52109633e+00,\n",
       "        -1.64326856e+00, -1.12948561e+00, -2.89466354e-01,\n",
       "        -1.21666689e+00, -7.30674960e-01, -7.15536901e-01,\n",
       "        -2.86870144e-01, -6.27818491e-01, -8.12037423e-01,\n",
       "        -1.31688992e+00, -3.33090407e-01, -4.87510009e-01,\n",
       "        -7.04618174e-01, -1.56909290e+00, -9.00287256e-01,\n",
       "         2.33368268e+00, -6.19670239e-01, -8.99137065e-01,\n",
       "        -2.05567949e+00, -7.94235272e-01, -3.97058814e-01,\n",
       "        -7.97663138e-02, -4.14345261e-01, -8.72590813e-01,\n",
       "        -4.21064783e-01, -4.21064783e-01, -4.21064783e-01,\n",
       "        -1.06888937e+00, -1.07496701e+00, -2.17735757e-02,\n",
       "        -3.55085874e-03, -8.24080955e-01, -7.29447453e-01,\n",
       "        -2.18236413e-01,  4.91687057e-01,  7.94368628e-01,\n",
       "         1.39756533e-01,  1.95598847e+00,  1.39756533e-01,\n",
       "         1.39756533e-01, -1.50816345e+00, -4.94685929e-01,\n",
       "        -1.67724265e-01, -7.90779996e-02, -8.68036359e-01,\n",
       "        -2.52101040e-01, -8.79869715e-01, -1.42828348e+00,\n",
       "        -1.77737622e-02, -1.31003418e-02, -6.93320034e-01,\n",
       "        -4.52457251e-01, -2.77030562e-02, -5.21565416e-03,\n",
       "        -3.69800874e-01, -4.99069715e-01, -1.86542775e-01,\n",
       "        -1.86542775e-01, -8.04854468e-01, -5.22823895e-01,\n",
       "        -1.71525192e+00, -1.32693655e+00, -1.02955832e+00,\n",
       "        -2.85705274e-01, -9.59665417e-01,  8.95438355e-01,\n",
       "        -5.91149822e-01, -2.22818622e+00, -1.04698883e+00,\n",
       "        -8.21067525e-01,  1.10176625e+00, -4.39193233e-02,\n",
       "        -7.85976803e-01, -1.08018123e+00, -5.19160770e-01,\n",
       "        -3.55085874e-03, -3.55085874e-03, -5.69525840e-01,\n",
       "         2.39939585e+00, -4.09077457e-01, -1.91131817e+00,\n",
       "        -6.58036719e-01, -1.53724962e+00, -1.35943162e+00,\n",
       "        -1.16617427e+00, -9.57241363e-01, -7.93862472e-01,\n",
       "         1.02214044e+00, -8.49539000e-01, -3.85584559e-01,\n",
       "        -1.11705192e+00, -6.47971487e-01, -6.76452178e-02,\n",
       "        -5.32728572e-01, -7.97663138e-02, -7.97663138e-02,\n",
       "        -7.94327392e-01, -3.48046170e-01, -2.86870144e-01,\n",
       "         1.31625620e+00,  1.39756533e-01,  1.39756533e-01,\n",
       "        -4.26509436e-01, -1.94726818e+00, -8.14566481e-01,\n",
       "        -1.01691950e+00, -1.76186237e+00, -7.92383130e-01,\n",
       "        -1.12995462e+00, -5.98530971e-01, -7.64652388e-01,\n",
       "        -2.26986832e-02, -3.97304799e-03, -1.19987067e+00,\n",
       "        -1.13561637e+00, -5.57126491e-01, -8.87645492e-01,\n",
       "        -9.23983639e-01, -7.76047789e-01, -1.30186252e+00,\n",
       "         2.92529448e+00,  1.07393468e-01,  9.80905036e-01,\n",
       "        -9.18273052e-01, -1.29844785e+00, -1.18801725e+00,\n",
       "        -1.12170504e-01, -5.22902959e-01, -8.84552026e-01,\n",
       "        -5.80360575e-01, -1.84843773e-01,  1.11701179e+00,\n",
       "        -1.49982869e+00, -9.56132631e-01, -6.48919354e-01,\n",
       "        -5.09245496e-02, -2.71694756e-03, -8.94229862e-01,\n",
       "        -6.27222196e-01, -1.45531062e+00, -1.44132874e+00,\n",
       "        -1.44989876e+00, -1.46235042e+00, -8.86330318e-01,\n",
       "        -1.17369935e+00, -9.67756283e-01, -1.49892376e+00,\n",
       "        -1.06372539e+00, -1.13503044e+00, -5.79188164e-01,\n",
       "         2.08639137e+00, -6.35509382e-01, -2.60748594e-01,\n",
       "        -2.60748594e-01, -2.60748594e-01, -4.92099430e-01,\n",
       "        -4.76921163e-01,  6.60465512e-01, -6.69300860e-01,\n",
       "        -1.55570661e+00,  7.98009349e-01, -8.52299864e-01,\n",
       "        -1.74684974e-02, -1.74684974e-02, -5.76355773e-01,\n",
       "         1.65791745e-01, -3.21535445e-01, -6.71850365e-01,\n",
       "        -1.17292809e-01,  6.91817407e-01, -5.56914878e-01,\n",
       "        -1.17292809e-01, -7.86134289e-01, -8.38175257e-01,\n",
       "        -5.52539931e-01, -1.71299071e-01, -1.71299071e-01,\n",
       "         3.05697327e-01, -8.53778464e-01,  9.81931724e-02,\n",
       "        -9.86894469e-01, -4.02183607e-01, -5.88966017e-01,\n",
       "        -3.49369947e-02, -1.74684974e-02, -1.74684974e-02,\n",
       "        -1.74684974e-02, -1.74684974e-02, -1.35190722e+00,\n",
       "        -1.16198181e-01, -6.56824090e-01, -7.92369564e-02,\n",
       "        -9.85005863e-01,  9.15040801e-02, -3.04389671e-01,\n",
       "        -2.54370229e+00, -3.56800443e-01, -3.42598142e-01,\n",
       "        -1.71299071e-01, -1.15175628e+00,  7.80233311e-01,\n",
       "         1.53072589e+00, -5.60587489e-01, -3.42598142e-01,\n",
       "        -1.71299071e-01, -1.71299071e-01,  3.66457235e-01,\n",
       "        -8.63694971e-01, -5.50005042e-01, -9.23462048e-02,\n",
       "        -9.67252388e-01,  1.06262625e+00, -2.88425609e-01,\n",
       "        -2.88425609e-01, -2.88425609e-01, -2.88425609e-01,\n",
       "        -1.02849512e+00, -6.75424275e-02, -6.75424275e-02,\n",
       "        -1.17292809e-01, -1.17292809e-01, -1.67058788e-01,\n",
       "        -1.67058788e-01, -6.75424275e-02, -6.75424275e-02,\n",
       "         9.63430775e-01,  1.96962447e-02,  1.48313564e+00,\n",
       "         5.75267732e-01, -6.49189019e-03, -2.20452564e-01,\n",
       "        -7.75131205e-02, -7.30205220e-01, -5.31630691e-01,\n",
       "        -2.25346676e-01, -5.51208286e-01, -6.05524380e-01,\n",
       "        -7.23538146e-01, -1.22784251e-01, -7.27477759e-01,\n",
       "         4.88425446e-01, -6.02482584e-02, -4.32505023e-01,\n",
       "         1.36268571e-01, -6.00919811e-01, -1.74684974e-02,\n",
       "        -1.74684974e-02, -1.74684974e-02, -1.74684974e-02,\n",
       "        -1.67058788e-01, -1.67058788e-01, -1.67058788e-01,\n",
       "         3.44592628e-01, -4.77183577e-01, -1.53867670e-02,\n",
       "        -4.05202134e-01,  1.34456336e-02, -7.52805144e-01,\n",
       "        -1.84057191e-01, -1.67058788e-01, -1.67058788e-01,\n",
       "        -1.51404275e-01, -6.20049960e-01, -3.75914701e-01,\n",
       "         4.76313187e-01, -4.65549325e-01,  1.37097213e-01,\n",
       "        -1.20627931e-01, -1.20627931e-01, -1.12170504e-01,\n",
       "        -1.25351306e+00, -3.45494136e-01, -6.10352068e-01,\n",
       "         1.50733097e-01, -4.56754554e-01, -9.23506047e-01,\n",
       "        -1.99017974e+00, -1.24837657e+00, -1.24521479e+00,\n",
       "        -1.84643918e+00, -4.44701605e-01,  6.48511149e-01,\n",
       "         3.11069314e-01,  1.26084593e+00, -1.09173446e-01,\n",
       "        -1.09173446e-01,  3.48919548e-01, -3.34172964e-01,\n",
       "        -6.75424275e-02, -6.75424275e-02, -8.03073792e-01,\n",
       "        -1.16001347e+00, -6.75424275e-02, -6.75424275e-02,\n",
       "        -6.75424275e-02, -4.17550159e-04, -5.34345986e-02,\n",
       "        -9.37125599e-01, -2.83258384e-02, -1.06930181e+00,\n",
       "        -1.06877752e+00, -9.08500218e-01, -1.17292809e-01,\n",
       "        -1.17292809e-01,  4.81498080e-01, -9.68278043e-01,\n",
       "        -1.10825521e+00,  1.00080741e+00, -3.83491063e-01,\n",
       "        -2.60748594e-01, -2.60748594e-01, -4.17612337e-01,\n",
       "        -2.39539179e-01,  3.65708732e-01,  2.20502228e-02,\n",
       "        -4.69854802e-02, -7.31716457e-03, -1.90688843e+00,\n",
       "         6.21256741e-01, -1.02502486e+00, -6.79815162e-01,\n",
       "        -6.03901727e-03,  8.09217807e-02, -3.73522722e-01,\n",
       "        -1.44415690e+00, -3.18529401e-01, -6.31458652e-01,\n",
       "        -3.45803138e-01, -5.46125503e-01, -8.15978984e-01,\n",
       "        -5.53024426e-01,  5.92645182e-01, -1.37855262e+00,\n",
       "        -9.73808196e-01, -1.25094034e+00, -1.09748994e-01,\n",
       "        -1.09173446e-01, -1.57504955e-01, -1.09173446e-01,\n",
       "        -1.09173446e-01, -8.91239268e-01, -1.06586110e+00,\n",
       "        -6.32809613e-01, -7.55202186e-01, -1.04544344e+00,\n",
       "         3.47798839e-01, -8.69000994e-01, -5.26418431e-01,\n",
       "        -1.09173446e-01, -1.09173446e-01, -2.40869953e-01,\n",
       "        -1.51536634e+00, -5.13278710e-01, -6.53894216e-01,\n",
       "         1.31378124e+00,  3.32838324e-01, -7.32244846e-01,\n",
       "        -3.37750579e-01, -1.90391128e-01,  4.05450069e-02,\n",
       "        -1.17292809e-01, -1.17292809e-01, -1.83740026e-01,\n",
       "        -7.97663138e-02, -5.20426645e-01, -1.09243980e-01,\n",
       "        -7.97663138e-02,  1.11847854e+00, -1.53996350e+00,\n",
       "        -7.24128218e-01,  3.63636173e-01,  6.85661821e-01,\n",
       "         2.98234015e-01, -1.55374368e-01, -6.11729318e-01,\n",
       "        -2.41910986e-01, -5.35483528e-01, -2.96109274e-01,\n",
       "        -5.47026596e-01,  9.39067412e-02, -1.71299071e-01,\n",
       "        -1.71299071e-01, -4.00856483e-01,  1.89106661e-01,\n",
       "        -2.60748594e-01, -2.60748594e-01, -5.45771380e-01,\n",
       "        -5.10956742e-01,  3.33323063e-02, -4.09113223e-01,\n",
       "        -1.71141072e+00,  5.64089788e-01, -6.00256311e-01,\n",
       "         1.24830604e-01, -2.63439741e-01, -1.25073152e+00,\n",
       "        -1.54420367e+00, -6.70042902e-02, -4.58407762e-02,\n",
       "        -1.04211224e-02, -8.71049189e-01, -2.68609865e-01,\n",
       "        -2.10106150e+00,  5.56414654e-01,  1.62132327e-01,\n",
       "        -1.32173686e+00, -2.89278976e-01, -1.17292809e-01,\n",
       "        -1.17292809e-01, -4.04825966e-01, -1.51910926e-01,\n",
       "        -1.00070743e-01,  9.40232099e-02,  1.61367492e-01,\n",
       "        -7.97663138e-02, -7.97663138e-02, -9.23309470e-02,\n",
       "        -1.30225279e+00, -4.54822715e-01, -1.67058788e-01,\n",
       "        -1.67058788e-01, -7.57248881e-01,  4.59951782e-01,\n",
       "        -7.19363028e-01, -2.64602112e-01, -2.88425609e-01,\n",
       "        -3.57880848e-02, -1.21427198e+00, -5.30068251e-01,\n",
       "        -1.25758001e+00,  4.96330876e-01,  3.95718146e-01,\n",
       "        -8.91338415e-01, -3.49604996e-01, -3.33090407e-01,\n",
       "        -3.33090407e-01, -2.32336406e-03,  1.39756533e-01,\n",
       "         1.39756533e-01,  1.39756533e-01, -1.86093302e-01,\n",
       "         4.61988038e-01, -4.36615233e-01,  1.03413277e-02,\n",
       "         6.04153281e-01, -5.05528914e-01, -1.35765248e+00,\n",
       "         4.25816657e-01, -2.09939333e-01, -7.42011967e-02,\n",
       "        -1.56411748e+00,  3.81848439e-01, -7.39027726e-01,\n",
       "        -8.88952691e-01, -7.05601076e-01,  2.15913686e+00,\n",
       "         4.73606410e-01, -1.20627931e-01, -1.20627931e-01,\n",
       "        -1.66668898e-01,  2.70211407e-01, -3.34567615e-01,\n",
       "         4.80384038e-01,  5.22141839e-01, -2.82451446e-01,\n",
       "         2.93647238e-02,  1.39756533e-01,  1.39756533e-01,\n",
       "        -1.44492138e+00, -1.06661802e+00,  9.14688400e-02,\n",
       "         4.58648044e-01,  2.28238733e+00, -1.01832847e+00,\n",
       "        -9.11288783e-02,  3.65628944e-01, -3.87736477e-01,\n",
       "        -1.74684974e-02, -1.53867670e-02, -6.59431180e-01,\n",
       "        -5.29777147e-01,  3.00754854e-01, -9.29315114e-01,\n",
       "        -6.50364960e-01, -5.79417609e-01,  5.34726323e-01,\n",
       "        -1.43563557e-01, -3.27275463e-01, -1.19697477e+00,\n",
       "        -1.86542775e-01, -1.86542775e-01, -1.15981625e+00,\n",
       "        -4.43129694e-01, -9.83760945e-02, -1.48463669e-01,\n",
       "        -5.08648453e-01, -2.79593841e-01, -7.88584714e-01,\n",
       "         3.27753404e-01,  3.42840870e-02,  9.13826493e-01,\n",
       "        -2.69757473e-01,  4.63740502e-01, -3.81355152e-01,\n",
       "         6.68231750e-01,  3.55074358e-02, -4.41583035e-01,\n",
       "        -1.02890311e+00,  1.37176498e+00,  7.43360992e-02,\n",
       "        -1.09173446e-01, -1.09173446e-01,  1.39756533e-01,\n",
       "         1.39756533e-01, -4.77804260e-01, -4.54828062e-01,\n",
       "        -1.07321591e-01, -1.07321591e-01, -5.09220418e-01,\n",
       "        -4.77812156e-01, -1.99135586e+00, -1.30608759e+00,\n",
       "        -1.10556564e+00, -6.69399980e-01, -1.31307384e+00,\n",
       "        -5.59945114e-01, -1.89378582e+00, -3.55910723e-01,\n",
       "        -7.80881686e-01, -2.18588652e-01, -3.32840381e-01,\n",
       "         1.35431473e-01, -9.61319780e-02, -5.32252646e-01,\n",
       "         1.92301586e-01, -2.60748594e-01, -2.60748594e-01,\n",
       "        -2.60748594e-01, -2.42981380e-01,  1.31643324e-01,\n",
       "         2.25893468e-02,  4.66916283e-02,  1.42910401e-01,\n",
       "        -3.59594504e-01,  3.34291248e-01, -7.93410985e-01,\n",
       "        -1.53025737e+00,  2.13261863e-01, -3.98743091e-01,\n",
       "         1.71770481e+00, -2.78508266e-01, -3.91994599e-01,\n",
       "        -8.61881425e-01, -1.09173446e-01, -1.09173446e-01,\n",
       "        -6.33813585e-01, -1.03058309e-01, -2.98688601e-01,\n",
       "        -8.50747680e-01, -2.85291271e-01, -1.12170504e-01,\n",
       "        -1.12170504e-01, -1.40337880e+00, -2.26538805e-01,\n",
       "         4.37053984e-01,  4.63962384e-01, -6.47596895e-01,\n",
       "        -1.16169635e-01, -4.84966398e-01,  4.61462957e-01,\n",
       "        -3.23967342e-01, -9.97628278e-01, -5.33270659e-02,\n",
       "        -2.09137838e-01, -1.15969414e+00,  2.97999939e-01,\n",
       "        -1.94719537e-01, -1.87065747e-01, -1.13648761e-01,\n",
       "        -3.49369947e-02, -1.74684974e-02,  1.01282273e+00,\n",
       "         8.71473544e-02,  3.09868419e-01, -4.73632754e-02,\n",
       "        -9.60382437e-01, -2.07362070e-01,  3.51880729e-01,\n",
       "        -3.72120680e-01,  9.17390796e-02,  2.23192551e+00,\n",
       "        -1.15809081e-01, -1.74684974e-02, -1.74684974e-02,\n",
       "        -1.74684974e-02, -1.74684974e-02, -1.74684974e-02,\n",
       "         2.34357450e+00, -4.71462395e-01, -1.67058788e-01,\n",
       "        -1.67058788e-01, -9.19621777e-01,  2.61007026e-01,\n",
       "         4.85984744e-01, -1.90406778e+00,  3.61247932e-01,\n",
       "        -4.19992296e-01,  9.11634456e-01, -1.17292809e-01,\n",
       "         1.69820533e-02, -2.36499623e-01, -6.71414689e-02,\n",
       "        -3.13950734e-01, -9.24504604e-01,  2.90014999e-01,\n",
       "         3.44524001e-01, -1.20430752e+00,  4.12711610e-01,\n",
       "        -7.85672932e-01,  3.12838170e-01,  1.04207573e+00,\n",
       "         1.16477449e+00,  4.79969064e-01, -1.41890094e+00,\n",
       "        -4.99422328e-01, -9.80802189e-01,  4.58778067e-01,\n",
       "        -4.41021911e-01,  2.43645732e-01, -9.92420395e-01,\n",
       "        -4.16791024e-05, -5.34850260e-02, -1.13989627e-01,\n",
       "        -8.96716780e-01,  3.19970652e-01, -1.19222842e+00,\n",
       "        -6.42315268e-01, -2.88425609e-01, -2.88425609e-01,\n",
       "        -2.60748594e-01, -2.60748594e-01, -2.60748594e-01,\n",
       "        -6.93429166e-01,  4.66342856e-02, -7.94037239e-01,\n",
       "        -1.46484594e+00, -1.49115403e-01, -8.80019731e-01,\n",
       "        -1.20629969e+00, -8.11336208e-01, -8.72709142e-01,\n",
       "        -3.48756041e-01,  2.70186407e-01, -8.76329835e-01,\n",
       "        -7.38995784e-01, -9.83304781e-01, -3.69677575e-01,\n",
       "        -3.79045611e-01, -2.02094624e-01,  8.09878092e-01,\n",
       "        -4.55948688e-01, -7.61969112e-01, -1.19636866e+00,\n",
       "        -9.13506093e-01, -1.05710598e+00, -4.38145378e-01,\n",
       "        -1.01989127e-01, -5.69879363e-01, -1.67058788e-01,\n",
       "         5.09982647e-02, -3.38225888e-01, -1.86542775e-01,\n",
       "        -2.88425609e-01, -2.88425609e-01, -5.76678427e-03,\n",
       "        -1.07336518e+00, -2.84603143e-01,  5.44028088e-01,\n",
       "         1.63358507e+00, -1.67058788e-01, -1.67058788e-01,\n",
       "        -1.75345956e-01, -1.67058788e-01,  4.45620123e-01,\n",
       "        -5.38611987e-01, -2.42981380e-01,  1.33699633e-01,\n",
       "        -4.71947828e-01, -9.58261685e-01,  5.76699134e-03,\n",
       "         1.41622954e-01, -1.88916300e-01,  7.36164117e-02,\n",
       "         2.69982774e-01, -1.32999397e+00,  2.29202791e-01,\n",
       "        -1.17292809e-01, -1.17292809e-01,  8.44766500e-01,\n",
       "        -5.31678554e-01, -3.19774113e-01, -1.23287283e+00,\n",
       "        -3.16466354e-01, -6.80178353e-01, -1.86542775e-01,\n",
       "        -1.86542775e-01,  3.49999606e-02,  8.57499420e-02,\n",
       "        -1.40276445e+00, -2.05239434e+00, -7.03202730e-01,\n",
       "        -1.35120959e+00,  4.72635744e-01, -1.79386303e+00,\n",
       "        -9.06250139e-01, -1.21780117e+00, -8.21446043e-02,\n",
       "        -3.55085874e-03, -3.11960604e-03, -1.06280182e+00,\n",
       "         1.09998896e-01,  2.24875900e-01,  8.93394119e-01,\n",
       "        -5.56449037e-01,  1.83335918e-01, -6.39526331e-01,\n",
       "         2.66298377e-01, -1.21116209e-01, -1.09173446e-01,\n",
       "        -1.09173446e-01, -1.42875938e-01, -9.34311993e-01,\n",
       "        -4.66789866e-01, -6.75424275e-02, -6.75424275e-02,\n",
       "        -6.75424275e-02, -1.18849558e+00, -4.01433375e-01,\n",
       "        -1.86542775e-01, -1.86542775e-01,  2.53888737e-01,\n",
       "         4.98414673e-01, -2.93342900e-01, -2.61497973e-01,\n",
       "        -1.09173446e-01, -1.07401616e-01, -2.63379869e-01,\n",
       "         7.10972649e-01, -2.88425609e-01, -2.88425609e-01,\n",
       "        -2.88425609e-01, -3.74179949e-01,  8.74829435e-01,\n",
       "        -1.08751824e+00,  2.40184076e-01, -4.23866400e-01,\n",
       "         6.59386929e-02, -1.37997200e+00, -3.56810117e-01,\n",
       "        -4.66863376e-01,  1.11559920e-01, -4.15442992e-01,\n",
       "        -9.28725996e-02, -1.25081271e-01,  2.53072112e-01,\n",
       "        -7.17186491e-01, -1.21666427e+00, -5.27371513e-01,\n",
       "        -1.09173446e-01, -1.09173446e-01,  7.65032263e-01,\n",
       "        -7.60056755e-01, -1.21815441e+00, -1.60393931e+00,\n",
       "        -7.26883302e-01,  9.44366502e-02, -4.49378228e-01,\n",
       "        -1.09173446e-01, -1.07401616e-01, -6.31776862e-01,\n",
       "        -5.50398698e-01, -1.15233252e+00, -6.75424275e-02,\n",
       "        -6.75424275e-02,  2.72551033e+00, -2.29620596e-01,\n",
       "         3.44226017e-01,  3.34959565e-02, -7.55108035e-01,\n",
       "         3.69070184e-02,  1.69382329e+00,  1.72423550e+00,\n",
       "        -3.51563040e-01,  1.20272466e+00,  2.20953547e-01,\n",
       "        -4.44371871e-01, -3.13683289e-01, -6.78365413e-01,\n",
       "         5.50035886e-01, -2.42993487e-01, -4.40413828e-02,\n",
       "        -8.35925341e-01, -8.11762956e-03, -1.71299071e-01,\n",
       "        -1.71299071e-01,  3.48752710e-01,  1.18956783e-01,\n",
       "        -6.02344122e-01, -3.31432370e-01, -1.64813902e-01,\n",
       "        -3.13363515e-01, -1.07320977e+00, -7.74137387e-01,\n",
       "         7.33392160e-01, -5.49078705e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "LogisticRegr.fit(x_train, y_train)\n",
    "LogisticRegr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the train data set\n",
    "prediction_reg=LogisticRegr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94574807584006\n"
     ]
    }
   ],
   "source": [
    "# Lets measure the score\n",
    "score = LogisticRegr.score(x_train, y_train)\n",
    "print(score)\n",
    "\n",
    "# score is nothing but the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29574   146]\n",
      " [ 1588   654]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "y_train.shape\n",
    "prediction_reg.shape\n",
    "\n",
    "cm = metrics.confusion_matrix(y_train, prediction_reg)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94574807584006"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc=(cm[0][0] + cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29170383586083853"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Senstivity\n",
    "sens=cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950874831763122"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifisity\n",
    "spec=cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "prec=cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950874831763122"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall: Same as Specifisity\n",
    "rec=spec\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8975942127451034"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 Score\n",
    "(2*prec*rec)/(prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value of F1 Score on Train data is around 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#?</th>\n",
       "      <th>#??</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Doc_ID  #2016   #?  #??  #affirmation  #affirmations  \\\n",
       "0  0           1       0.0    0.0  0.0  0.0           0.0             \n",
       "1  1           2       0.0    0.0  0.0  0.0           0.0             \n",
       "2  2           3       0.0    0.0  0.0  0.0           0.0             \n",
       "3  3           4       0.0    0.0  0.0  0.0           0.0             \n",
       "4  4           5       0.0    0.0  0.0  0.0           0.0             \n",
       "\n",
       "   #allahsoil  #altwaystoheal  #altwaystoheal  #healthy  ...  yes  yet   yo  \\\n",
       "0  0.0         0.0             0.0                       ...  0.0  0.0  0.0   \n",
       "1  0.0         0.0             0.0                       ...  0.0  0.0  0.0   \n",
       "2  0.0         1.0             1.0                       ...  0.0  0.0  0.0   \n",
       "3  0.0         0.0             0.0                       ...  1.0  0.0  0.0   \n",
       "4  0.0         0.0             0.0                       ...  0.0  0.0  0.0   \n",
       "\n",
       "   you  you!  you.  you?  young  id  tweet_y  \n",
       "0  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "1  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "2  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "3  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "4  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try and calculate the value on test data\n",
    "# importing test_DTM.csv file\n",
    "test_df=pd.read_csv(\"test_DTM.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Doc_ID', '#2016', '#?', '#??', '#affirmation',\n",
       "       '#affirmations', '#allahsoil', '#altwaystoheal',\n",
       "       '#altwaystoheal  #healthy',\n",
       "       ...\n",
       "       'yes', 'yet', 'yo', 'you', 'you!', 'you.', 'you?', 'young', 'id',\n",
       "       'tweet_y'],\n",
       "      dtype='object', length=880)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the x_test\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 875)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 'Unnamed: 0' and 'Doc_ID' column\n",
    "pos=[i not in ['Unnamed: 0','Doc_ID','dummy','id','label','tweet_y'] for i in test_df.columns ]\n",
    "x_test=test_df[test_df.columns[pos]]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running them Model on x_test\n",
    "# Make predictions on the train data set\n",
    "prediction_reg=LogisticRegr.predict(x_test)\n",
    "prediction_reg[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=[i == 1 for i in prediction_reg]\n",
    "sum(pos) # Total tweets labelled as 1 are 466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  0\n",
       "0  1       0\n",
       "1  2       0\n",
       "2  3       0\n",
       "3  4       0\n",
       "4  5       0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_complete=pd.concat([test_df['Doc_ID'],pd.DataFrame(list(prediction_reg))],axis=1)\n",
    "Test_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  label\n",
       "0  1       0    \n",
       "1  2       0    \n",
       "2  3       0    \n",
       "3  4       0    \n",
       "4  5       0    "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_complete.columns=['Doc_ID','label']\n",
    "Test_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0  0    \n",
       "1  0    \n",
       "2  0    \n",
       "3  0    \n",
       "4  0    "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the Doc_ID as this is not required for submission\n",
    "Test_complete2=Test_complete.drop(['Doc_ID'],axis=1)\n",
    "Test_complete2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing it back to the folder \n",
    "Test_complete2.to_csv(\"test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
