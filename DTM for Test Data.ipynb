{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data set\n",
    "#dr=\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\"\n",
    "df_test=pd.read_csv(\"test_tweets.csv\",encoding=\"ISO-8859-1\")\n",
    "df_test.head()\n",
    "\n",
    "# There are three columns\n",
    "# 1: id\n",
    "# 2: tweet (text form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data set\n",
    "# creating the stop word list\n",
    "# Removing rows corresponding to stop word\n",
    "# Stop word removal using inbuilt and custom list\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop2=list(stop)\n",
    "stop2.extend(['@user','@user @user','&amp;','@user @user @user','-','u','Ã¢Â€Â“',\n",
    "             'Ã¢Â€Â”','Ã¢Â€Â¦','Ã¢Â†Â','Ã¢ÂÂ¤','Ã¢ÂÂ¤Ã¯Â¸Â','Ã°ÂŸÂ’Â•','Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "             'Ã°ÂŸÂ”Â','Ã°ÂŸÂ”Â  #love','Ã°ÂŸÂ”Â  #love  #instagood',\n",
    "             'Ã°ÂŸÂ˜','Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â„',\n",
    "            'Ã°ÂŸÂ˜ÂŠ','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â”','Ã°ÂŸÂ˜Â˜','Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "            'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦','Ã°ÂŸÂ˜Â¢',\n",
    "             'Ã¢Â€Â¦','!!','!!!','Ã¢Â€Â¦',\n",
    "             'Ã¢Â€Â¦',\n",
    "'2',\n",
    "'Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "'...','Ã¢Â†Â','4','1','3',\n",
    "'Ã°ÂŸÂ˜ÂŠ','Ã¢ÂÂ¤Ã¯Â¸Â','.@user','#a','5',':(','Ã°ÂŸÂ˜Â','Ã¢Â€Â“',\n",
    "'..','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â”','10','Ã°ÂŸÂ˜Â','1st','7','Ã°ÂŸÂ˜Â¢','#Ã¢Â€Â¦','6',\n",
    "'Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â˜','Ã°ÂŸÂ’Â•','Ã°ÂŸÂ”Â','Ã¢ÂÂ¤','Ã°ÂŸÂ˜Â„',\n",
    "'Ã°ÂŸÂ”Â  #love','50','2nd','8','Ã¢Â€Â”','Ã°ÂŸÂ˜','3d:',\n",
    "'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91  ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
    "              'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘Â…Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We need to analyse the text data stored in the 'tweet' column\n",
    "# Before that lets define some key functions\n",
    "# Creating functions to do toeknisation and punctuation removal\n",
    "\n",
    "# White space tokenizer\n",
    "def tokenize(text):\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    token = []\n",
    "    for item in text:\n",
    "        token.append(tokenizer.tokenize(item))\n",
    "        \n",
    "    # Removing stop words\n",
    "    ls_dummy1=[]\n",
    "    ls_dummy2=[]\n",
    "    temp=1\n",
    "    for i in token:\n",
    "        ls_dummy1=[]\n",
    "        for j in i:\n",
    "            if j in stop2:\n",
    "                temp=1\n",
    "            else:\n",
    "                ls_dummy1.append(j)\n",
    "        ls_dummy2.append(ls_dummy1)\n",
    "    l3=ls_dummy2\n",
    "        \n",
    "    return l3\n",
    "\n",
    "# Creating a function for removing the puntuation from text\n",
    "def rem_punctuation(data_frame,colname):\n",
    "    l3=[]\n",
    "    l2=[i for i in data_frame[colname]]\n",
    "    l3=tokenize(l2)\n",
    "\n",
    "    # Removing the punctuations\n",
    "    l5=[]\n",
    "    l6=[]\n",
    "    for j in l3:\n",
    "        for k in j:\n",
    "            if k in string.punctuation:\n",
    "                temp=1\n",
    "            else:\n",
    "                l5.append(k)\n",
    "        l6.append(l5)\n",
    "        l5=[]\n",
    "    c_ls=[\" \".join(i) for i in l6]\n",
    "    df1=pd.DataFrame(c_ls)\n",
    "    df1.columns=['Text']\n",
    "    return(df1)\n",
    "\n",
    "# We will now create a function that takes in text and ngram list\n",
    "# text/document is stores in a list\n",
    "# list also specifies ngram paramter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# The function should take the column containing text data\n",
    "def TF_NGRAM(data_frame,colname,ngram):\n",
    "    # Tokenize the data\n",
    "    DocID_ls=[]\n",
    "\n",
    "    #Appending the Doc_ID column\n",
    "    data_frame['Doc_ID']=[i for i in range(1,data_frame[colname].shape[0]+1)]\n",
    "\n",
    "\n",
    "    from nltk import ngrams       \n",
    "    l1=[]\n",
    "    for i in data_frame['Doc_ID']:\n",
    "        for k in data_frame[data_frame['Doc_ID']==i][colname]:\n",
    "            for j in ngram:\n",
    "                unigrams = ngrams(k.split(), j)\n",
    "                for z in unigrams:\n",
    "                    if j==1:\n",
    "                        l1.append(z[0])\n",
    "                    elif j==2:\n",
    "                        l1.append(z[0] + \" , \" +z[1])\n",
    "                    elif j==3:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2])\n",
    "                    elif j==4:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2] +\" , \" +z[3])\n",
    "\n",
    "                    DocID_ls.append(i)\n",
    "\n",
    "    # Creating a Data Frame out of it\n",
    "\n",
    "    s1=pd.Series(l1)\n",
    "    s2=pd.Series(DocID_ls)\n",
    "    df1=pd.DataFrame(s2)\n",
    "    df1['s1']=s1\n",
    "    df1.columns=['Doc_ID','Tokens']\n",
    "    df1\n",
    "    return(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you look closely, there are certain characters such as Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¿Ã¢ÂœÂ (row 4 for instance)\n",
    "# These are meaningless and hence they need to be removed\n",
    "# Removing the special character/ascii character\n",
    "twt=[str(i).encode('ascii', 'ignore').decode(\"utf-8\") for i in df_test['tweet'] ]\n",
    "df_test['tweet']=twt\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# removing the special characters doesnt reduce the number of records \n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#white #supremacists want everyone see new ?? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways heal #acne!! #altwaystoheal #healthy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hp cursed child book reservations already? yes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd #bihday amazing, hilarious #nephew eli ahm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  #studiolife #aislife #requires #passion #dedic...\n",
       "1  #white #supremacists want everyone see new ?? ...\n",
       "2  safe ways heal #acne!! #altwaystoheal #healthy...\n",
       "3  hp cursed child book reservations already? yes...\n",
       "4  3rd #bihday amazing, hilarious #nephew eli ahm..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuations, stop words etc\n",
    "df=rem_punctuation(df_test,'tweet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#white #supremacists want everyone see new ?? ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways heal #acne!! #altwaystoheal #healthy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hp cursed child book reservations already? yes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd #bihday amazing, hilarious #nephew eli ahm...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Doc_ID\n",
       "0  #studiolife #aislife #requires #passion #dedic...       1\n",
       "1  #white #supremacists want everyone see new ?? ...       2\n",
       "2  safe ways heal #acne!! #altwaystoheal #healthy...       3\n",
       "3  hp cursed child book reservations already? yes...       4\n",
       "4  3rd #bihday amazing, hilarious #nephew eli ahm...       5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Doc_ID']=range(1,df.shape[0]+1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# So no rows were removed during punctuation and stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#len(np.where(df['Text'].applymap(lambda x: x == ''))[0]) # 19 ff them\n",
    "blnk_Doc_ID=df['Text']==\"\"\n",
    "df[blnk_Doc_ID].shape\n",
    "\n",
    "# There are 9 Doc_ID which are blank after Removing punctuations, stop words etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2425      2426\n",
       "4157      4158\n",
       "4187      4188\n",
       "8776      8777\n",
       "10079    10080\n",
       "10511    10512\n",
       "13016    13017\n",
       "14155    14156\n",
       "14348    14349\n",
       "Name: Doc_ID, dtype: int32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the Doc_ID's that have blank in 'Text'\n",
    "ls_blnk_Doc_ID=df[blnk_Doc_ID]['Doc_ID']\n",
    "ls_blnk_Doc_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#studiolife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#aislife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>#requires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#passion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>#dedication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID       Tokens\n",
       "0       1  #studiolife\n",
       "1       1     #aislife\n",
       "2       1    #requires\n",
       "3       1     #passion\n",
       "4       1  #dedication"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram frequency analysis\n",
    "# checking the ngram distribution\n",
    "ngram_df=TF_NGRAM(df,'Text',[1,2,3])\n",
    "ngram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17188"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of unique 'Doc_ID' in ngram_df\n",
    "len(ngram_df['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#studiolife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#aislife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>#requires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#passion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>#dedication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID       Tokens\n",
       "0       1  #studiolife\n",
       "1       1     #aislife\n",
       "2       1    #requires\n",
       "3       1     #passion\n",
       "4       1  #dedication"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Replace all , in Tokens with \"\"\n",
    "import re\n",
    "ngram_df['Tokens']=ngram_df['Tokens'].apply(lambda x: re.sub(',','',x))\n",
    "ngram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If we add the Doc_ID  that had blanks in df, then we would get 17197 which is the \n",
    "# total count of Doc_ID in the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID Tokens\n",
       "0       1  dummy\n",
       "1       2  dummy\n",
       "2       3  dummy\n",
       "3       4  dummy\n",
       "4       5  dummy"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Data Frame that has 'dummy' values for all Doc_ID\n",
    "#ls_blnk_Doc_ID=list(blnk_Doc_ID)\n",
    "\n",
    "blnk_df=pd.DataFrame(df['Doc_ID'],columns=['Doc_ID'])\n",
    "blnk_df['Tokens']='dummy'\n",
    "blnk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17197"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Binding ngram_df and blnk_df row wise\n",
    "ngram_df2=pd.concat([ngram_df,blnk_df],axis=0)\n",
    "len(ngram_df2['Doc_ID'].unique())\n",
    "# Now all the Doc_IDs are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#aislife</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#aislife  #requires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>#aislife  #requires  #passion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#dedication</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>#dedication  #willpower</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID                         Tokens  Frequency\n",
       "0       1                       #aislife          1\n",
       "1       1            #aislife  #requires          1\n",
       "2       1  #aislife  #requires  #passion          1\n",
       "3       1                    #dedication          1\n",
       "4       1        #dedication  #willpower          1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a summary at Doc_ID and Tokens level\n",
    "ngram_df2['Frequency']=1\n",
    "ngram_df0=ngram_df2.groupby(['Doc_ID','Tokens'])['Frequency'].sum().reset_index()\n",
    "ngram_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Reading the tokens obtained during the analyses of train data set\n",
    "# They are stored in the token.csv\n",
    "token=pd.read_csv(\"tokens.csv\")\n",
    "token=[i for i in token['index']]\n",
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>find</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>??</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID    Tokens  Frequency\n",
       "19       1     dummy          1\n",
       "20       1      find          1\n",
       "34       2        ??          2\n",
       "38       2     dummy          1\n",
       "39       2  everyone          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creating the DTM\n",
    "# Taking 'material','money','benefits' as Features\n",
    "\n",
    "pos=[i in token for i in ngram_df0['Tokens']] # filtering on the tokens given in 'token' list\n",
    "ngram_df_DTM0=ngram_df0[pos]\n",
    "ngram_df_DTM0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Tokens</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#?</th>\n",
       "      <th>#??</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Tokens  Doc_ID  #2016   #?  #??  #affirmation  #affirmations  #allahsoil  \\\n",
       "0            1    0.0  0.0  0.0           0.0            0.0         0.0   \n",
       "1            2    0.0  0.0  0.0           0.0            0.0         0.0   \n",
       "2            3    0.0  0.0  0.0           0.0            0.0         0.0   \n",
       "3            4    0.0  0.0  0.0           0.0            0.0         0.0   \n",
       "4            5    0.0  0.0  0.0           0.0            0.0         0.0   \n",
       "\n",
       "Tokens  #altwaystoheal  #altwaystoheal  #healthy  #amazing  ...  year  years  \\\n",
       "0                  0.0                       0.0       0.0  ...   0.0    0.0   \n",
       "1                  0.0                       0.0       0.0  ...   0.0    0.0   \n",
       "2                  1.0                       1.0       0.0  ...   0.0    0.0   \n",
       "3                  0.0                       0.0       0.0  ...   0.0    0.0   \n",
       "4                  0.0                       0.0       0.0  ...   0.0    0.0   \n",
       "\n",
       "Tokens  yes  yet   yo  you  you!  you.  you?  young  \n",
       "0       0.0  0.0  0.0  0.0   0.0   0.0   0.0    0.0  \n",
       "1       0.0  0.0  0.0  0.0   0.0   0.0   0.0    0.0  \n",
       "2       0.0  0.0  0.0  0.0   0.0   0.0   0.0    0.0  \n",
       "3       1.0  0.0  0.0  0.0   0.0   0.0   0.0    0.0  \n",
       "4       0.0  0.0  0.0  0.0   0.0   0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 877 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivotting df3 \n",
    "ngram_df_DTM0=ngram_df_DTM0.pivot(index='Doc_ID',columns='Tokens',values='Frequency').fillna(0).reset_index()\n",
    "ngram_df_DTM0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 877)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df_DTM0.shape\n",
    "# ngram_df_DTM has all the Doc_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 879)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the lebel column to ngram_df_DTM\n",
    "# Joining this with the 'id' column from input data frame(df_test) to bring in the labels \n",
    "\n",
    "# LEFT JOIN\n",
    "ngram_df_DTM=pd.merge(ngram_df_DTM0,df_test,left_on='Doc_ID',right_on='id',how='left')\n",
    "ngram_df_DTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving ngram_df_DTM into a csv file so that the other program can use it\n",
    "ngram_df_DTM.to_csv(\"test_DTM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
